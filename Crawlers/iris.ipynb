{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import mysql.connector\n",
    "from mysql.connector import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"크롤러 메인 함수\"\"\"\n",
    "    # 실행 전 체크포인트 확인\n",
    "    print_checkpoint('iris')\n",
    "    \n",
    "    print(\"iris 크롤링 시작...\")\n",
    "    base_url = \"https://www.iris.go.kr/contents/retrieveBsnsAncmBtinSituListView.do\"\n",
    "    \n",
    "    # 데이터 수집\n",
    "    #announcements = get_announcement_list(base_url, start_page=1, end_page=1)\n",
    "    announcements = get_announcement_list(base_url, start_page=1, end_page=None)\n",
    "\n",
    "    print(\"\\n최종 결과:\")\n",
    "    print(f\"총 {len(announcements)}개의 공고 수집 완료\")\n",
    "    \n",
    "    # DB 저장\n",
    "    connection = connect_to_database()\n",
    "    if connection:\n",
    "        insert_into_db(connection, announcements)\n",
    "        connection.close()\n",
    "    \n",
    "    # 크롤링 후 체크포인트 확인\n",
    "    print_checkpoint('iris')\n",
    "    \n",
    "    print(\"크롤링 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹드라이버 설정\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    \n",
    "    # 리눅스 환경에서의 추가 설정\n",
    "    chrome_options.add_argument('--headless')  # 헤드리스 모드 실행\n",
    "    chrome_options.add_argument('--no-sandbox')  # 샌드박스 비활성화\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')  # 공유 메모리 사용 비활성화\n",
    "    chrome_options.add_argument('--disable-gpu')  # GPU 하드웨어 가속 비활성화\n",
    "    \n",
    "    # 기존 설정들\n",
    "    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    chrome_options.add_argument('--window-size=1920,1080')\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "    # 크롬 드라이버 생성 시 에러 처리\n",
    "    try:\n",
    "        driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=chrome_options\n",
    "        )\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"드라이버 설정 중 오류 발생: {e}\")\n",
    "        \n",
    "        # 대체 방법 시도\n",
    "        try:\n",
    "            print(\"대체 방법으로 드라이버 설정 시도...\")\n",
    "            chrome_options.add_argument('--remote-debugging-port=9222')\n",
    "            driver = webdriver.Chrome(\n",
    "                options=chrome_options\n",
    "            )\n",
    "            return driver\n",
    "        except Exception as sub_e:\n",
    "            print(f\"대체 방법도 실패: {sub_e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_announcement_detail_selenium(driver):\n",
    "    \"\"\"상세 페이지에서 공고 정보를 추출하는 함수\"\"\"\n",
    "    try:\n",
    "        data = {\n",
    "            'POSTDATE': None,\n",
    "            'ANNOUNCEMENT_NUMBER': None,\n",
    "            'TITLE': None,\n",
    "            'CATEGORY': None,\n",
    "            'LOCATION': \"전국\",  # 기본값\n",
    "            'CONTENT': None,\n",
    "            'START': None,\n",
    "            'END': None,\n",
    "            'AGENCY': None,\n",
    "            'LINK': driver.current_url,\n",
    "            'FILE': None,\n",
    "            'KEYWORD': None\n",
    "        }\n",
    "        \n",
    "        # 기본 정보 추출\n",
    "        info_items = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.title_area .list_dot li'))\n",
    "        )\n",
    "        \n",
    "        for item in info_items:\n",
    "            text = item.text.strip()\n",
    "            if '소관부처' in text:\n",
    "                continue  # 소관부처는 건너뜀\n",
    "            elif '전문기관' in text:\n",
    "                data['AGENCY'] = text.split('전문기관')[1].strip()\n",
    "            elif '공고번호' in text:\n",
    "                data['ANNOUNCEMENT_NUMBER'] = text.split('공고번호')[1].strip()\n",
    "            elif '공고명' in text:\n",
    "                data['TITLE'] = text.split('공고명')[1].strip()\n",
    "            elif '접수기간' in text:\n",
    "                period = text.split('접수기간')[1].strip()\n",
    "                if '~' in period:\n",
    "                    start_date, end_date = period.split('~')\n",
    "                    data['START'] = start_date.strip().replace('.', '-')\n",
    "                    data['END'] = end_date.strip().replace('.', '-')\n",
    "            elif '공고일자' in text:\n",
    "                date_text = text.split('공고일자')[1].strip()\n",
    "                data['POSTDATE'] = date_text.replace('.', '-')\n",
    "        \n",
    "        # 내용 추출\n",
    "        content = None\n",
    "        content_selectors = [\n",
    "            '.se-contents',          # 기존 선택자\n",
    "            '.tb_contents',          # 다른 가능한 선택자\n",
    "            '.content_wrap',         # 다른 가능한 선택자\n",
    "            '.board_contents',       # 다른 가능한 선택자\n",
    "            '.brd_view_content'      # 다른 가능한 선택자\n",
    "        ]\n",
    "        \n",
    "        for selector in content_selectors:\n",
    "            try:\n",
    "                content_div = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                if content_div:\n",
    "                    content = content_div.text.strip()\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if content:\n",
    "            data['CONTENT'] = clean_content(content)\n",
    "            \n",
    "            # 지역 정보 추출\n",
    "            locations = ['서울', '경기', '인천', '강원', '충북', '충남', '대전', '세종', \n",
    "                        '전북', '전남', '광주', '경북', '경남', '대구', '울산', '부산', '제주']\n",
    "            \n",
    "            # 제목, 내용에서 지역 언급 횟수 계산\n",
    "            location_count = {}\n",
    "            search_text = f\"{data['TITLE']} {data['CONTENT']}\"\n",
    "            \n",
    "            for loc in locations:\n",
    "                count = search_text.count(loc)\n",
    "                if count > 0:\n",
    "                    location_count[loc] = count\n",
    "            \n",
    "            # 가장 많이 언급된 지역이 있으면 해당 지역으로 설정\n",
    "            if location_count:\n",
    "                most_mentioned = max(location_count.items(), key=lambda x: x[1])\n",
    "                if most_mentioned[1] >= 2:  # 최소 2회 이상 언급된 경우에만 지역으로 설정\n",
    "                    data['LOCATION'] = most_mentioned[0]\n",
    "        \n",
    "        # 첨부파일 목록 추출\n",
    "        files = []\n",
    "        file_elements = driver.find_elements(By.CSS_SELECTOR, '.add_file .text')\n",
    "        for elem in file_elements:\n",
    "            files.append(elem.text.strip())\n",
    "        \n",
    "        if files:\n",
    "            data['FILE'] = ', '.join(files)\n",
    "            \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"상세 페이지 데이터 추출 중 오류: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_announcement_list(base_url, start_page=1, end_page=None):\n",
    "    \"\"\"공고 목록을 수집하는 메인 함수\"\"\"\n",
    "    checkpoint = CrawlerCheckpoint('iris')\n",
    "    announcements = []\n",
    "    current_page = start_page\n",
    "    \n",
    "    try:\n",
    "        driver = setup_driver()\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                # 페이지 URL 생성 및 이동\n",
    "                if current_page == 1:\n",
    "                    driver.get(base_url)\n",
    "                else:\n",
    "                    page_url = f\"{base_url}?pageIndex={current_page}\"\n",
    "                    driver.get(page_url)\n",
    "                time.sleep(2)\n",
    "                \n",
    "                # 페이지 로딩 대기\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, '.dbody li'))\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"페이지 로딩 시간 초과: {e}\")\n",
    "                    break\n",
    "\n",
    "                # BeautifulSoup으로 현재 페이지 파싱\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                items = soup.select('.dbody li')\n",
    "\n",
    "                if not items:\n",
    "                    print(\"공고를 찾을 수 없습니다. 마지막 페이지에 도달했거나 데이터가 없습니다.\")\n",
    "                    break\n",
    "\n",
    "                print(f\"\\n현재 페이지: {current_page}\")\n",
    "                print(f\"찾은 공고 개수: {len(items)}\")\n",
    "                \n",
    "                # 각 공고 항목 처리\n",
    "                for idx, item in enumerate(items, 1):\n",
    "                    try:\n",
    "                        # 기관 정보 추출\n",
    "                        inst_elem = item.select_one('.inst_title')\n",
    "                        if not inst_elem:\n",
    "                            print(f\"{idx}번 항목: 기관 정보를 찾을 수 없음\")\n",
    "                            continue\n",
    "                        agencies = inst_elem.text.strip().split(' > ')\n",
    "                        agency = agencies[-1].strip() if agencies else None\n",
    "                        \n",
    "                        # 기본 정보 추출\n",
    "                        info_div = item.select_one('.etc_info')\n",
    "                        if not info_div:\n",
    "                            print(f\"{idx}번 항목: 기본 정보를 찾을 수 없음\")\n",
    "                            continue\n",
    "                            \n",
    "                        spans = info_div.select('span')\n",
    "                        announcement_num = None\n",
    "                        post_date = None\n",
    "                        category = None\n",
    "                        \n",
    "                        for span in spans:\n",
    "                            text = span.text.strip()\n",
    "                            if '공고번호' in text:\n",
    "                                announcement_num = text.split(':')[1].strip()\n",
    "                            elif '공고일자' in text:\n",
    "                                post_date = text.split(':')[1].strip()\n",
    "                            elif '공모유형' in text:\n",
    "                                category = text.split(':')[1].strip()\n",
    "                        \n",
    "                        # 제목과 링크 추출\n",
    "                        title_elem = item.select_one('.title a')\n",
    "                        if not title_elem:\n",
    "                            print(f\"{idx}번 항목: 제목 요소를 찾을 수 없음\")\n",
    "                            continue\n",
    "                        \n",
    "                        title = title_elem.text.strip()\n",
    "                        onclick = title_elem.get('onclick', '')\n",
    "                        \n",
    "                        print(f\"\\n처리 중 ({current_page}페이지 {idx}/{len(items)}): {post_date}, {title}\")\n",
    "                        \n",
    "                        # 체크포인트 비교\n",
    "                        if checkpoint.last_crawled:\n",
    "                            if (post_date == checkpoint.last_crawled['last_post_date'] and \n",
    "                                title == checkpoint.last_crawled['last_title']):\n",
    "                                print(f\"\\n이전 수집 지점 도달. 크롤링 중단\")\n",
    "                                return announcements\n",
    "                        \n",
    "                        # 상세 페이지 ID 추출\n",
    "                        if not onclick:\n",
    "                            print(f\"onclick 속성이 없음: {title}\")\n",
    "                            continue\n",
    "                            \n",
    "                        detail_id = re.search(r\"f_bsnsAncmBtinSituListForm_view\\('([^']+)'\", onclick)\n",
    "                        if not detail_id:\n",
    "                            print(f\"상세 페이지 ID를 찾을 수 없음: {onclick}\")\n",
    "                            continue\n",
    "                        \n",
    "                        detail_url = f\"https://www.iris.go.kr/contents/retrieveBsnsAncmView.do?ancmId={detail_id.group(1)}\"\n",
    "                        \n",
    "                        # 새 탭에서 상세 페이지 열기\n",
    "                        try:\n",
    "                            driver.execute_script(f\"window.open('{detail_url}', '_blank');\")\n",
    "                            time.sleep(2)\n",
    "                            \n",
    "                            driver.switch_to.window(driver.window_handles[-1])\n",
    "                            \n",
    "                            # 상세 페이지 데이터 수집\n",
    "                            announcement_data = get_announcement_detail_selenium(driver)\n",
    "                            \n",
    "                            if announcement_data:\n",
    "                                announcement_data.update({\n",
    "                                    'POSTDATE': post_date.replace('.', '-') if post_date else None,\n",
    "                                    'ANNOUNCEMENT_NUMBER': announcement_num,\n",
    "                                    'TITLE': title,\n",
    "                                    'CATEGORY': category,\n",
    "                                    'AGENCY': agency,\n",
    "                                })\n",
    "                                \n",
    "                                if len(announcements) == 0:\n",
    "                                    checkpoint.save_checkpoint(post_date, title)\n",
    "                                \n",
    "                                announcements.append(announcement_data)\n",
    "                                print(f\"수집 완료: {title}\")\n",
    "                            \n",
    "                        finally:\n",
    "                            # 상세 페이지 탭 닫기\n",
    "                            if len(driver.window_handles) > 1:\n",
    "                                driver.close()\n",
    "                                driver.switch_to.window(driver.window_handles[0])\n",
    "                                time.sleep(2)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"공고 처리 중 오류: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # 다음 페이지 확인 및 이동\n",
    "                try:\n",
    "                    # 현재 페이지 정보 확인\n",
    "                    page_info = driver.find_element(By.CLASS_NAME, 'current_page')\n",
    "                    total_page = int(page_info.text.split('/')[-1].strip())\n",
    "                    print(f\"\\n전체 페이지: {total_page}\")\n",
    "                    \n",
    "                    if current_page < total_page:\n",
    "                        print(f\"\\n{current_page + 1}페이지로 이동...\")\n",
    "                        # URL로 직접 다음 페이지 이동\n",
    "                        next_page = current_page + 1\n",
    "                        next_url = f\"{base_url}?pageIndex={next_page}\"\n",
    "                        driver.get(next_url)\n",
    "                        current_page = next_page\n",
    "                        time.sleep(3)\n",
    "                        \n",
    "                        if end_page and current_page > end_page:\n",
    "                            print(f\"지정된 마지막 페이지({end_page})에 도달했습니다.\")\n",
    "                            break\n",
    "                    else:\n",
    "                        print(\"마지막 페이지입니다.\")\n",
    "                        break\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"페이징 처리 중 오류: {e}\")\n",
    "                    break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"페이지 처리 중 오류: {e}\")\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"크롤링 중 오류 발생: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "    \n",
    "    print(f\"\\n수집 완료 - 총 {len(announcements)}건\")\n",
    "    return announcements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(date_str):\n",
    "    \"\"\"날짜 문자열을 YYYY-MM-DD 형식으로 변환\"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        # 다양한 날짜 형식 처리\n",
    "        date_str = date_str.replace('.', '-').strip()\n",
    "        if len(date_str) == 10:  # YYYY-MM-DD\n",
    "            return date_str\n",
    "        return None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(text):\n",
    "   \"\"\"HTML 태그 및 특수문자 제거\"\"\"\n",
    "   if not text:\n",
    "       return text\n",
    "       \n",
    "   # HTML 태그 제거\n",
    "   text = re.sub(r'<[^>]+>', '', text)\n",
    "   \n",
    "   # HTML 특수문자 변환 및 제거\n",
    "   html_chars = {\n",
    "       '&nbsp;': ' ',\n",
    "       '&#39;': \"'\",\n",
    "       '&quot;': '\"', \n",
    "       '&lt;': '<',\n",
    "       '&gt;': '>',\n",
    "       '&amp;': '&',\n",
    "       '&middot;': '',  # middot 제거\n",
    "       '&bull;': '',    # 글머리 기호 제거\n",
    "       '&rarr;': '',    # 화살표 제거\n",
    "       '&raquo;': '',   # 이중 화살표 제거\n",
    "       '&laquo;': '',   # 이중 화살표 제거\n",
    "       '&ndash;': '-',  # 대시\n",
    "       '&mdash;': '-',  # 대시\n",
    "   }\n",
    "   \n",
    "   for char, replace in html_chars.items():\n",
    "       text = text.replace(char, replace)\n",
    "   \n",
    "   # 나머지 HTML 엔티티 제거 (&로 시작하는 모든 특수문자)\n",
    "   text = re.sub(r'&[a-zA-Z0-9#]+;', '', text)\n",
    "   \n",
    "   # 공고 번호 형식의 텍스트 제거\n",
    "   text = re.sub(r'중소벤처기업부 공고 제\\d{4}-\\d+호', '', text)\n",
    "   \n",
    "   # 연속된 공백 제거\n",
    "   text = re.sub(r'\\s+', ' ', text)\n",
    "   \n",
    "   # 앞뒤 공백 제거\n",
    "   text = text.strip()\n",
    "   \n",
    "   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file_info(files):\n",
    "   \"\"\"파일 정보에서 파일명만 추출하고 문자열로 변환\"\"\"\n",
    "   if not files:\n",
    "       return None\n",
    "       \n",
    "   file_names = []\n",
    "   for file in files:\n",
    "       if 'name' in file:\n",
    "           # 파일명과 크기 분리\n",
    "           name = file['name'].split('  ')[0]  # 파일 크기 정보 제거\n",
    "           file_names.append(name)\n",
    "   \n",
    "   # 리스트를 문자열로 변환 (쉼표로 구분)\n",
    "   return ', '.join(file_names) if file_names else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(text):\n",
    "    \"\"\"텍스트에서 지역 정보 추출\"\"\"\n",
    "    locations = ['서울', '경기', '인천', '강원', '충북', '충남', '대전', '세종', \n",
    "                '전북', '전남', '광주', '경북', '경남', '대구', '울산', '부산', '제주']\n",
    "    \n",
    "    location_count = {}\n",
    "    for loc in locations:\n",
    "        count = text.count(loc)\n",
    "        if count > 0:\n",
    "            location_count[loc] = count\n",
    "    \n",
    "    if location_count:\n",
    "        # 가장 많이 언급된 지역 반환\n",
    "        return max(location_count.items(), key=lambda x: x[1])[0]\n",
    "    return \"전국\"  # 기본값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "class CrawlerCheckpoint:\n",
    "    def __init__(self, site_name):\n",
    "        self.site_name = site_name\n",
    "        # 현재 작업 디렉토리를 기준으로 경로 설정\n",
    "        self.checkpoint_file = os.path.join('checkpoints', f'{site_name}_last_crawled.json')\n",
    "        self.last_crawled = self.load_checkpoint()\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        \"\"\"체크포인트 파일 로드\"\"\"\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.makedirs('checkpoints')\n",
    "            \n",
    "        if os.path.exists(self.checkpoint_file):\n",
    "            with open(self.checkpoint_file, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        return None\n",
    "        \n",
    "    def save_checkpoint(self, post_date, title):\n",
    "        \"\"\"최신 크롤링 정보 저장\"\"\"\n",
    "        try:\n",
    "            checkpoint_data = {\n",
    "                'last_post_date': post_date,\n",
    "                'last_title': title,\n",
    "                'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "            \n",
    "            # checkpoints 디렉토리가 없으면 생성\n",
    "            if not os.path.exists('checkpoints'):\n",
    "                os.makedirs('checkpoints')\n",
    "            \n",
    "            with open(self.checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            self.last_crawled = checkpoint_data\n",
    "            print(f\"체크포인트 저장 완료\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"체크포인트 저장 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 확인을 위한 함수 추가\n",
    "def print_checkpoint(site_name='iris'):\n",
    "    checkpoint = CrawlerCheckpoint(site_name)\n",
    "    if checkpoint.last_crawled:\n",
    "        print(\"\\n현재 저장된 체크포인트:\")\n",
    "        print(f\"마지막 수집 날짜: {checkpoint.last_crawled['last_post_date']}\")\n",
    "        print(f\"마지막 수집 제목: {checkpoint.last_crawled['last_title']}\")\n",
    "        print(f\"업데이트 시간: {checkpoint.last_crawled['updated_at']}\")\n",
    "    else:\n",
    "        print(\"\\n저장된 체크포인트가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_database():\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host='10.100.54.176',          # DB 호스트\n",
    "            database='ALRIMI',         # DB 이름\n",
    "            user='root',      # DB 사용자명\n",
    "            password='ibdp',   # DB 비밀번호\n",
    "            charset='utf8mb4',\n",
    "            collation='utf8mb4_general_ci'\n",
    "        )\n",
    "        return connection\n",
    "    except Error as e:\n",
    "        print(f\"DB 연결 오류: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_db(connection, announcements):\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO Crawler (\n",
    "                POSTDATE, ANNOUNCEMENT_NUMBER, TITLE, \n",
    "                CATEGORY, LOCATION, CONTENT, \n",
    "                START, END, AGENCY, \n",
    "                LINK, FILE, KEYWORD\n",
    "            ) VALUES (\n",
    "                %s, %s, %s, %s,\n",
    "                %s, %s, %s, %s, \n",
    "                %s, %s, %s, %s\n",
    "            )\n",
    "        \"\"\"\n",
    "        \n",
    "        for announcement in announcements:\n",
    "            # 각 필드에 대해 길이 제한 설정\n",
    "            announcement_number = announcement.get('ANNOUNCEMENT_NUMBER')\n",
    "            if announcement_number and len(announcement_number) > 50:\n",
    "                announcement_number = announcement_number[:50]\n",
    "\n",
    "            title = announcement.get('TITLE')\n",
    "            if title and len(title) > 300:\n",
    "                title = title[:300]\n",
    "\n",
    "            category = announcement.get('CATEGORY')\n",
    "            if category and len(category) > 20:\n",
    "                category = category[:20]\n",
    "\n",
    "            content = announcement.get('CONTENT')\n",
    "            if content and len(content) > 4000:\n",
    "                content = content[:4000]\n",
    "\n",
    "            start = announcement.get('START')\n",
    "            if start and len(start) > 10:\n",
    "                start = start[:10]\n",
    "\n",
    "            agency = announcement.get('AGENCY')\n",
    "            if agency and len(agency) > 100:\n",
    "                agency = agency[:100]\n",
    "\n",
    "            link = announcement.get('LINK')\n",
    "            if link and len(link) > 300:\n",
    "                link = link[:300]\n",
    "\n",
    "            keyword = announcement.get('KEYWORD')\n",
    "            if keyword and len(keyword) > 100:\n",
    "                keyword = keyword[:100]\n",
    "\n",
    "            file = announcement.get('FILE')\n",
    "            if file and len(file) > 200:\n",
    "                file = file[:200]\n",
    "\n",
    "            values = (\n",
    "                announcement.get('POSTDATE'),\n",
    "                announcement_number,\n",
    "                title,\n",
    "                category,\n",
    "                announcement.get('LOCATION'),\n",
    "                content,\n",
    "                start,\n",
    "                announcement.get('END'),\n",
    "                agency,\n",
    "                link,\n",
    "                file,\n",
    "                keyword\n",
    "            )\n",
    "            \n",
    "            cursor.execute(insert_query, values)\n",
    "        \n",
    "        connection.commit()\n",
    "        print(f\"{len(announcements)}개의 공고가 DB에 저장되었습니다.\")\n",
    "        \n",
    "    except Error as e:\n",
    "        print(f\"데이터 저장 중 오류 발생: {e}\")\n",
    "        connection.rollback()\n",
    "    \n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "저장된 체크포인트가 없습니다.\n",
      "iris 크롤링 시작...\n",
      "\n",
      "현재 페이지: 1\n",
      "찾은 공고 개수: 10\n",
      "\n",
      "처리 중 (1페이지 1/10): 2024-10-31, 2024년도 제3차 신재생에너지R&D 신규지원대상 연구개발과제 공고\n",
      "체크포인트 저장 완료\n",
      "수집 완료: 2024년도 제3차 신재생에너지R&D 신규지원대상 연구개발과제 공고\n",
      "\n",
      "처리 중 (1페이지 2/10): 2024-10-29, 2025년도 NCP 활동지원사업 신규과제 공모\n",
      "수집 완료: 2025년도 NCP 활동지원사업 신규과제 공모\n",
      "\n",
      "처리 중 (1페이지 3/10): 2024-10-25, 2024년도 글로벌 의사과학자 양성사업(의사과학자 양성 사무국 운영)신규지원 대상과제 공고\n",
      "수집 완료: 2024년도 글로벌 의사과학자 양성사업(의사과학자 양성 사무국 운영)신규지원 대상과제 공고\n",
      "\n",
      "처리 중 (1페이지 4/10): 2024-10-25, 2024년도 한-호주 Tech-Bridge 프로그램 신규 과제 공모\n",
      "수집 완료: 2024년도 한-호주 Tech-Bridge 프로그램 신규 과제 공모\n",
      "\n",
      "처리 중 (1페이지 5/10): 2024-10-18, 2024년도 제2차 한국형 ARPA-H 프로젝트 신규지원 대상과제 통합공고\n",
      "수집 완료: 2024년도 제2차 한국형 ARPA-H 프로젝트 신규지원 대상과제 통합공고\n",
      "\n",
      "처리 중 (1페이지 6/10): 2024-10-16, 2025년도 팬데믹 대비 mRNA 백신 개발 지원사업 대상과제 공고\n",
      "수집 완료: 2025년도 팬데믹 대비 mRNA 백신 개발 지원사업 대상과제 공고\n",
      "\n",
      "처리 중 (1페이지 7/10): 2024-10-15, 2025년 농업연구개발사업 1차공모\n",
      "수집 완료: 2025년 농업연구개발사업 1차공모\n",
      "\n",
      "처리 중 (1페이지 8/10): 2024-03-19, 2024년도 팁스(TIPS) 창업기업 지원계획 통합공고\n",
      "수집 완료: 2024년도 팁스(TIPS) 창업기업 지원계획 통합공고\n",
      "\n",
      "처리 중 (1페이지 9/10): 2023-12-01, 2024년_사회밀착형감염병원천기술개발_2020년 선정_2단계2연차_연차실적계획서 접수\n",
      "수집 완료: 2024년_사회밀착형감염병원천기술개발_2020년 선정_2단계2연차_연차실적계획서 접수\n",
      "\n",
      "처리 중 (1페이지 10/10): 2023-10-23, 2024년_공백품목_2021년 선정_2단계1연차_단계보고서 접수\n",
      "수집 완료: 2024년_공백품목_2021년 선정_2단계1연차_단계보고서 접수\n",
      "\n",
      "전체 페이지: 2\n",
      "\n",
      "2페이지로 이동...\n",
      "\n",
      "현재 페이지: 2\n",
      "찾은 공고 개수: 2\n",
      "\n",
      "처리 중 (2페이지 1/2): 2023-10-23, 2024년_함께달리기_2021년 선정_2단계1연차_단계보고서 접수\n",
      "수집 완료: 2024년_함께달리기_2021년 선정_2단계1연차_단계보고서 접수\n",
      "\n",
      "처리 중 (2페이지 2/2): 2022-12-05, 해외우수과학자유치사업 (Brain Pool / Brain Pool+) 2023년도 3차 신규과제 공고\n",
      "수집 완료: 해외우수과학자유치사업 (Brain Pool / Brain Pool+) 2023년도 3차 신규과제 공고\n",
      "\n",
      "전체 페이지: 2\n",
      "마지막 페이지입니다.\n",
      "\n",
      "수집 완료 - 총 12건\n",
      "\n",
      "최종 결과:\n",
      "총 12개의 공고 수집 완료\n",
      "12개의 공고가 DB에 저장되었습니다.\n",
      "\n",
      "현재 저장된 체크포인트:\n",
      "마지막 수집 날짜: 2024-10-31\n",
      "마지막 수집 제목: 2024년도 제3차 신재생에너지R&D 신규지원대상 연구개발과제 공고\n",
      "업데이트 시간: 2024-11-12 00:23:57\n",
      "크롤링 완료\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
